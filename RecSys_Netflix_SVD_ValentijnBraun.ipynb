{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Introduction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The applications of recommender systems in businesses have become increasingly popular. Recommender systems apply various sources of information including demographics, social, and preferences to provide users with tailored recommended items. Moreover, the favoured technique for building recommender systems is Collaborative filtering. This technique is further divided into three main categories including Memory-Based, Model-Based, and Hybrid-BAsed. Therefore, as large businesses realise the advantages of recommending personalized items to users, the research for techniques, sources of information, and implementation grows. Netflix is among the big organisations interested in the expansion of recommmender system. The application of recommender systems at Netflix is widely known, however improvements are continiously being investigated to provide users with the best movie and series recommendations. Thus, this notebook aims to investigate the application of collaborative filtering techniques for Netflix.      "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Which type of RecSys based on CF could Netflix user to provide the most accurate recommendations to users?\n",
    "\n",
    "- What are the different type of RecSys based on CF?\n",
    "- Which types could be used for Netflix' dataset?\n",
    "- How do KNN and SVD compare?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Importing Libraries"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General imports\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Used for visualisations in the EDA\n",
    "import seaborn as sns\n",
    "\n",
    "# Used in reducing the memory storage of sparse matrices\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "# Used for creating a KNN and SVD RecSys model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from scipy.sparse.linalg import svds\n",
    "\n",
    "# Used for performance evaluation\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# As working with NaN values in matrices overwelmed the output with warnings \n",
    "# these warnings will be ignored.\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "debugging = True"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Netflix Dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.1 Import Source Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code to append movieId to each record in all of the source files if this has not been executed earlier. This will allow all the source files to be loaded into a dataframe with one line of code and without having to add the movieId seperately before concatting the sourcefiles. This additionally resulted in a faster importing time of the source data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_netflix_source():\n",
    "    # Variable to keep track of which movieId has to be appended\n",
    "    x = 0\n",
    "    string = \",\"+str(x)\n",
    "\n",
    "    # Loop through each file in the directory\n",
    "    for filename in os.listdir(directory):\n",
    "        with open(os.path.join(directory, filename), 'r') as f:\n",
    "            # Check if the first line of the first file already has been formatted\n",
    "            # If true formatting the source will be skipped\n",
    "            if(f.readlines()[0] == '1:,1\\n'):\n",
    "                print('Source is already formatted, continuing \\n')\n",
    "                return\n",
    "            else:\n",
    "                print('Started formatting source files \\n')\n",
    "                # Append a ',', movieId and \\n (newline) to each line resulting in an extra column with movieId when using pandas read_csv \n",
    "                file_lines = [''.join([x.strip(), string, '\\n']) for x in f.readlines()]\n",
    "        with open(os.path.join(directory, filename), 'w') as f:\n",
    "            # Save the formatted file\n",
    "            f.writelines(file_lines)\n",
    "            print('Completed formatting source files')\n",
    "    return"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the movie dataframe by concatting all the sourcefiles without their title (skiprows=1). Concluding with naming the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source is already formatted, continuing \n",
      "\n",
      "Started concatting all source files to DataFrame \n",
      "\n",
      "Completed concatting all source files to DataFrame \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>rating</th>\n",
       "      <th>itemId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1488844</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>822109</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>885013</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    userId  rating  itemId\n",
       "0  1488844       3       1\n",
       "1   822109       5       1\n",
       "2   885013       4       1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the folder in which all the seperate movie files are located\n",
    "directory = \"/Users/vbraun/Downloads/training_set/\"\n",
    "\n",
    "# Run the function to format the source data if necessary\n",
    "format_netflix_source()\n",
    "\n",
    "print('Started concatting all source files to DataFrame \\n')\n",
    "# Performing 1 concat on all sourcefiles to create one dataframe (including itemId)\n",
    "# As the files do not have a header and differ between each other 'header' = None and the first row will be skipped\n",
    "netflix_df = pd.concat(pd.read_csv(os.path.join(directory, fname), skiprows=1,header=None) for fname in os.listdir(directory)).rename(columns={0:'userId',1:'rating',2:'date',3:'itemId'})\n",
    "print('Completed concatting all source files to DataFrame \\n')\n",
    "\n",
    "# Dropping the date column as this is not relevant for this recommender system\n",
    "netflix_df = netflix_df.drop(columns='date')\n",
    "\n",
    "display(netflix_df.head(3))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.2 Data Filtering"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To allow for faster development a debugging variable is used. If debugging is True the dataset will only consist of the first 100 movies. For the final model, debugging will be set to False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Debugging is set to True: limiting the dataset to the first 100 movies\n",
      "Length of selected dataset: 352771 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# In order to achieve faster execution time of the while developing a selection of the total dataset is made when debugging = True\n",
    "if debugging == True:\n",
    "    print('Debugging is set to True: limiting the dataset to the first 100 movies')\n",
    "    filtered_netflix_df = netflix_df[netflix_df['itemId'] <= 100]\n",
    "else:\n",
    "    filtered_netflix_df = netflix_df\n",
    "print('Length of selected dataset: {0} \\n'.format(len(filtered_netflix_df)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to filter the dataset based on activity and reduce the sparsity of the data, the data will be grouped and filtered based on movies and users. The datasets will show how many ratings each movie has gotten and how many rating each user has given."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To reduce the sparcity of data in the dataset, we will filter out the users that have rated fewer than 5% of the total amount of movies."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the movies that have been rated by fewer than 50 people will be filtered out of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering out users that have rated less than 5% of all movies\n",
      "Length of filtered dataset: 44209 \n",
      "\n",
      "Filtering out movies that have been rated by fewer than 50 users\n",
      "Length of filtered dataset: 44209\n"
     ]
    }
   ],
   "source": [
    "# Making two dataframes: One grouping items to show how many ratings an item has gotten and one grouping users to show how many ratings an user has given\n",
    "filtered_movie_count = filtered_netflix_df[['itemId','userId']].groupby('itemId').count().reset_index().rename(columns={'userId':'user_count'})\n",
    "filtered_user_count = filtered_netflix_df[['itemId','userId']].groupby('userId').count().reset_index().rename(columns={'itemId':'item_count'})\n",
    "\n",
    "# Defining the minimal percentage of items that a user has to have rated to be included\n",
    "required_rated_percentage = 0.05\n",
    "print('Filtering out users that have rated less than {0}% of all movies'.format(int(required_rated_percentage*100)))\n",
    "\n",
    "# Check if the userId exists when the total amount of items rated by a user (filtered_user_count['item_count']), divided by the total amount of movies (len(filtered_movie_count)' is bigger than the required_rated_percentage\n",
    "filtered_netflix_df = filtered_netflix_df[filtered_netflix_df['userId'].isin(filtered_user_count[filtered_user_count['item_count']/len(filtered_movie_count) > required_rated_percentage]['userId'])]\n",
    "print('Length of filtered dataset: {0} \\n'.format(len(filtered_netflix_df)))\n",
    "\n",
    "print('Filtering out movies that have been rated by fewer than {0} users'.format(50))\n",
    "filtered_netflix_df = filtered_netflix_df[filtered_netflix_df['itemId'].isin(filtered_movie_count[filtered_movie_count['user_count']>50]['itemId'])]\n",
    "print('Length of filtered dataset:',len(filtered_netflix_df))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Jester Dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.1 Import Source Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating dataframes for the jester datasets\n",
    "jester_items = pd.read_csv(r'C:\\Users\\vbraun\\Downloads\\SDM-Datasets\\jester_items.csv')\n",
    "jester_ratings = pd.read_csv(r'C:\\Users\\vbraun\\Downloads\\SDM-Datasets\\jester_ratings.csv')\n",
    "\n",
    "# Rename jokeId to itemId to have one uniform format for the Netflix and Jester dataset\n",
    "jester_df = jester_ratings.rename(columns={'jokeId':'itemId'})\n",
    "\n",
    "# The ratings given in the jester dataset range from -10 to 10. Since calculations including average ratings of users could be influenced by this, the ratings will be increase with 10 to range from 0 - 20. \n",
    "jester_df['rating'] = jester_df['rating'] + 10"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2 Data filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Debugging is set to True: limiting the dataset to the first 50 jokes\n",
      "Length of selected dataset: 715403 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# In order to achieve faster execution time of the while developing a selection of the total dataset is made when debugging = True\n",
    "if debugging == True:\n",
    "    print('Debugging is set to True: limiting the dataset to the first 50 jokes')\n",
    "    filtered_jester_df = jester_df[jester_df['itemId'] <= 50]\n",
    "else:\n",
    "    filtered_jester_df = jester_df\n",
    "print('Length of selected dataset: {0} \\n'.format(len(filtered_jester_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering out users that have rated less than 5% of all jokes\n",
      "Length of filtered dataset: 711239 \n",
      "\n",
      "Filtering out jokes that have been rated by fewer than 20 users\n",
      "Length of filtered dataset: 711239\n"
     ]
    }
   ],
   "source": [
    "# Making two dataframes: One grouping items to show how many ratings an item has gotten and one grouping users to show how many ratings an user has given\n",
    "jester_item_count = filtered_jester_df[['itemId','userId']].groupby('itemId').count().reset_index().rename(columns={'userId':'user_count'})\n",
    "jester_user_count = filtered_jester_df[['itemId','userId']].groupby('userId').count().reset_index().rename(columns={'itemId':'item_count'})\n",
    "\n",
    "# Defining the minimal percentage of items that a user has to have rated to be included\n",
    "required_rated_percentage = 0.05\n",
    "print('Filtering out users that have rated less than {0}% of all jokes'.format(int(required_rated_percentage*100)))\n",
    "\n",
    "# Check if the userId exists when the total amount of items rated by a user (jester_user_count['item_count']), divided by the total amount of movies (len(jester_item_count)' is bigger than the required_rated_percentage\n",
    "filtered_jester_df = filtered_jester_df[filtered_jester_df['userId'].isin(jester_user_count[jester_user_count['item_count']/len(jester_item_count) > required_rated_percentage]['userId'])]\n",
    "print('Length of filtered dataset: {0} \\n'.format(len(filtered_jester_df)))\n",
    "\n",
    "print('Filtering out jokes that have been rated by fewer than {0} users'.format(20))\n",
    "filtered_jester_df = filtered_jester_df[filtered_jester_df['itemId'].isin(jester_item_count[jester_item_count['user_count']>20]['itemId'])]\n",
    "print('Length of filtered dataset:',len(filtered_jester_df))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 EDA Netflix Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('The filtered dataset has', filtered_df['userId'].nunique(), 'unique users')\n",
    "# print('The filtered dataset has', filtered_df['itemId'].nunique(), 'unique movies')\n",
    "# print('The filtered dataset has', filtered_df['rating'].nunique(), 'unique ratings')\n",
    "# print('The unique ratings are', sorted(filtered_df['rating'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(filtered_df.head(),filtered_df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtered_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Amount of NaN values in the dataset:',filtered_df.loc[lambda x: x.isnull().any(axis=1)].shape[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following graph shows for each movie (as a dot) what its mean rating is in comparison to the total amount of ratings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt = sns.jointplot(x='rating_mean', y='rating_amount', data=filtered_df.groupby('itemId').agg(rating_mean = ('rating', 'mean'), rating_amount = ('rating', 'count')).reset_index())\n",
    "# plt.fig.suptitle(\"Rating Mean and Rating Amount of Movies\")\n",
    "# plt.fig.subplots_adjust(top=0.95)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notably, movies with low mean ratings have generally been rated a low number of times in relation to movies with a mean rating higher than 3.0."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next graph shows the same variables as the graph seen above for each user. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt = sns.jointplot(x='rating_mean', y='rating_amount', data=filtered_df.groupby('userId').agg(rating_mean = ('rating', 'mean'), rating_amount = ('rating', 'count')).reset_index())\n",
    "# plt.fig.suptitle(\"Rating Mean and Rating Amount of Users\")\n",
    "# plt.fig.subplots_adjust(top=0.95)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The graph for users show that there are several outliers of users that have rated many movies while having a low mean of their ratings. Additionally, the graph shows that mean of the rating mean approaches normality. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 EDA Jester Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('The filtered dataset has', filtered_df['userId'].nunique(), 'unique users')\n",
    "# print('The filtered dataset has', filtered_df['itemId'].nunique(), 'unique movies')\n",
    "# print('The filtered dataset has', filtered_df['rating'].nunique(), 'unique ratings')\n",
    "# print('The unique ratings are', sorted(filtered_df['rating'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(filtered_df.head(),filtered_df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtered_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Amount of NaN values in the dataset:',filtered_df.loc[lambda x: x.isnull().any(axis=1)].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt = sns.jointplot(x='rating_mean', y='rating_amount', data=filtered_df.groupby('itemId').agg(rating_mean = ('rating', 'mean'), rating_amount = ('rating', 'count')).reset_index())\n",
    "# plt.fig.suptitle(\"Rating Mean and Rating Amount of Movies\")\n",
    "# plt.fig.subplots_adjust(top=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt = sns.jointplot(x='rating_mean', y='rating_amount', data=filtered_df.groupby('userId').agg(rating_mean = ('rating', 'mean'), rating_amount = ('rating', 'count')).reset_index())\n",
    "# plt.fig.suptitle(\"Rating Mean and Rating Amount of Users\")\n",
    "# plt.fig.subplots_adjust(top=0.95)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 Recommender Systems"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both models will be evaluated using the same function that calculates the root mean squared error and the mean absolute error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_predictions(pred, truth):\n",
    "    # In order to only compare y's that were not 0, a selection is made from y and corresponding the y^ where y != 0 by using .nonzero() \n",
    "    pred = pred[truth.nonzero()].flatten()\n",
    "    truth = truth[truth.nonzero()].flatten()\n",
    "\n",
    "    # Standard RMSE and MAE calculations\n",
    "    rmse = np.sqrt(mean_squared_error(pred,truth))\n",
    "    mae = mean_absolute_error(pred,truth)\n",
    "    \n",
    "    return rmse, mae"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 K Nearest Neighbors (KNN)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.1 KNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test(filtered_df):\n",
    "    # Since the data is sparse the pivot_table is performed in the csr_matrix to reduce the required memory \n",
    "    sparse_matrix = csr_matrix(filtered_df.pivot_table(index='userId', columns='itemId', values='rating').fillna(0).values)\n",
    "    # print(sparse_matrix.check_format)\n",
    "\n",
    "    # To train and evaluate the KNN model the sparse matrix is split into 70% train, 15% validation and 15% test data\n",
    "    train_data, test_data = train_test_split(sparse_matrix, test_size=.01)\n",
    "    test_data, validation_data = train_test_split(test_data, test_size=.50)\n",
    "\n",
    "    return train_data, validation_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_weighted_knn_prediction(train_data, test_data, k = 5, metric = 'cosine'):\n",
    "    # Create the NearestNeighbors model with the parameters passed in the function\n",
    "    knn_model = NearestNeighbors(metric=metric,algorithm='brute',n_jobs=-1)\n",
    "\n",
    "    # Fit the model with the training data\n",
    "    knn_model_fitted = knn_model.fit(train_data.toarray())\n",
    "\n",
    "    # Find the closest distance with k amount of users for the passed 'test_data' (either the validation or test dataset depending on the stage)\n",
    "    distance, indices = knn_model_fitted.kneighbors(test_data.toarray(),k)\n",
    "\n",
    "    # Create a sorted list including the distances and userId for each user in the test_data that we can iterate through\n",
    "    sorted_distance_list = sorted(list(zip(indices.squeeze().tolist(), distance.squeeze().tolist())), key=lambda x: x[1])\n",
    "    \n",
    "    # Transform the train_data to be able to search by index\n",
    "    users_df = pd.DataFrame(train_data.toarray())\n",
    "\n",
    "    # We will now iterate through the list calculating the average ratings given for each item by the k most similar users \n",
    "    knn_prediction = []\n",
    "    for i, (idx, dist) in enumerate(sorted_distance_list):\n",
    "        inv = 1 / np.array(dist)\n",
    "        inv[inv == np.inf] = 10000\n",
    "        \n",
    "        sim_users = np.array(users_df[users_df.index.isin(idx)])\n",
    "        masked_ar = np.ma.masked_values(sim_users, 0)\n",
    "        masked_ar_av = np.ma.average(masked_ar,axis=0,weights=inv)\n",
    "        # Calculate the mean excluding NaN for each item and turn NaN values back to 0's (for items that have not been rated by all similar users) and add them to the prediction list\n",
    "        knn_prediction.append(masked_ar_av.data)\n",
    "\n",
    "    return np.array(knn_prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_unweighted_knn_prediction(train_data, test_data, k = 5, metric = 'cosine', n_neighbors = 20):\n",
    "    # Create the NearestNeighbors model with the parameters passed in the function\n",
    "    knn_model = NearestNeighbors(metric=metric,algorithm='brute',n_neighbors=n_neighbors,n_jobs=-1)\n",
    "\n",
    "    # Fit the model with the training data\n",
    "    knn_model_fitted = knn_model.fit(train_data.toarray())\n",
    "\n",
    "    # Find the closest distance with k amount of users for the passed 'test_data' (either the validation or test dataset depending on the stage)\n",
    "    distance, indices = knn_model_fitted.kneighbors(test_data.toarray(),k)\n",
    "\n",
    "    # Create a sorted list including the distances and userId for each user in the test_data that we can iterate through\n",
    "    sorted_distance_list = sorted(list(zip(indices.squeeze().tolist(), distance.squeeze().tolist())), key=lambda x: x[1])\n",
    "    \n",
    "    # Transform the train_data to be able to search by index\n",
    "    users_df = pd.DataFrame(train_data.toarray())\n",
    "\n",
    "    # We will now iterate through the list calculating the average ratings given for each item by the k most similar users \n",
    "    knn_prediction = []\n",
    "    for i, (idx, dist) in enumerate(sorted_distance_list):\n",
    "        # When calculating the mean rating we do not want to include 0's as these are items that have not been rated\n",
    "        # Therefore, all 0's in the matrix will be converted to NaN values so we can use np.nanmean to exclude these values\n",
    "        \n",
    "        # Find the ratings of the k most similar users\n",
    "        sim_users = np.array(users_df[users_df.index.isin(idx)])\n",
    "        # Replace 0's with NaN\n",
    "        sim_users[sim_users == 0] = np.nan\n",
    "        # Calculate the mean excluding NaN for each item and turn NaN values back to 0's (for items that have not been rated by all similar users) and add them to the prediction list\n",
    "        knn_prediction.append(np.nan_to_num(np.nanmean(sim_users,axis=0)))\n",
    "    \n",
    "    return np.array(knn_prediction)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.2 KNN Hyper Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyper_parameter_tuning_knn3(dataset,weighted=True, iterations = 10):\n",
    "    # n_neighbors = [2,5,10,15,20,30,50,75,100,250,1000]\n",
    "    n_neighbors = [10000,55000]\n",
    "    metric = ['euclidean','cosine','minkowski']\n",
    "\n",
    "    if weighted:\n",
    "        pred_function = calculate_weighted_knn_prediction\n",
    "    else:\n",
    "        pred_function = calculate_unweighted_knn_prediction\n",
    "\n",
    "    hpt_results = []\n",
    "    for met in metric:\n",
    "        for k in n_neighbors:\n",
    "            rmse_list = []\n",
    "            for i in range(0,iterations):\n",
    "                knn_train, knn_validation, knn_test = train_test(dataset)\n",
    "                rmse, mae = evaluate_predictions(pred_function(train_data = knn_train, test_data = knn_validation, metric = met, k = k),knn_validation.toarray())\n",
    "                rmse_list.append(rmse)\n",
    "              \n",
    "            print('For k = {0} using {1}, the average rmse = {2}'.format(k,met,(sum(rmse_list)/len(rmse_list))))\n",
    "            hpt_results.append([(sum(rmse_list)/len(rmse_list)),met,k])\n",
    "    print(hpt_results)\n",
    "    best_parameters_knn = sorted(hpt_results, key=lambda x: x[0])[0]\n",
    "    print(best_parameters_knn)\n",
    "\n",
    "    return best_parameters_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyper_parameter_tuning_knn(train_data, validation_data,weighted=True):\n",
    "    n_neighbors = [2,5,10,20,50,100,500]\n",
    "    metric = ['euclidean','cosine','minkowski']\n",
    "\n",
    "    if weighted:\n",
    "        pred_function = calculate_weighted_knn_prediction\n",
    "    else:\n",
    "        pred_function = calculate_unweighted_knn_prediction\n",
    "\n",
    "    hpt_results = []\n",
    "    for met in metric:\n",
    "        for k in n_neighbors:\n",
    "                \n",
    "            rmse, mae = evaluate_predictions(pred_function(train_data = train_data, test_data = validation_data, metric = met, k = k),validation_data.toarray())\n",
    "            \n",
    "            hpt_results.append([rmse,met,k])\n",
    "    print(hpt_results)\n",
    "    best_parameters_knn = sorted(hpt_results, key=lambda x: x[0])[0]\n",
    "    print(best_parameters_knn)\n",
    "\n",
    "    return best_parameters_knn"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Create NearestNeighbors model\n",
    "1. Fit the model with train data\n",
    "1. Use kneighbors to find the k amount of neighbors of the jokes in the test data\n",
    "1. Calculate the prediction by taking the average score of the k most similar jokes\n",
    "1. Evaluate the model by comparing the actual ratings with the predicted ratings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algorithm is set at brute (force) because the inputdata is sparse"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Singular Value Decomposition (SVD)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.1 SVD Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pivot the dataset into a matrix with index='userId', columns='itemId', values='rating' in order to later perform user-based collaborative filtering. Moreover, fill_value = 0 in order to remove NaN values and save them as 0. Finally, the matrix is directly stored as a sparse matrix to save memory, instead of first saving the entire matrix into memory. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scipy.sparse.linalg.svds was used to perform a partial singular value decomposition of a sparse matrix. This function allows us to specify 'k' which is the number of singular values and singular vectors that have to be computed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_svd_prediction(data, k = 5):\n",
    "    # Performing the SVD matrix factorisation giving: u (m x r) orthogonal matrix, \n",
    "    # s (r x r) diagonal matrix, and vt(ransposed) (r x n) orthogonal matrix.\n",
    "    u, s, vt = svds(data.toarray(), k = k)\n",
    "\n",
    "    # A diagonal matrix has to be created for s in order to recreate a matrix from u, s, and vt\n",
    "    s_diagonal = np.diag(s)\n",
    "\n",
    "    # Recreate the matrix by performing matrix multiplications of u, s, and vt\n",
    "    predictions = np.dot(np.dot(u, s_diagonal), vt)\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to evaluate the performance of the recommendations following SVD we only need the $\\hat{y}$ of existing $y$. Therefore, all other values will be filtered out of the prediction dataset by using pred[truth.nonzero()]. Afterwards we are able to evaluate the performance of our model by comparing $\\hat{y}$ with their corresponding $y$. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.2 SVD Hyper Parameter Tuning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different k values lead to different predictions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will perform hyperparameter tuning to find the k with the lowest rmse. For each k we will perform multiple iterations, in which a random sample of the data will be masked and used to calculate the rmse. The rmse of a k value will be the average rmse of all iterations of that k. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyper_parameter_tuning_svd(dataset, iterations = 10):\n",
    "    results = []\n",
    "    print('Calculating the average rmse over {0} iterations'.format(iterations))\n",
    "\n",
    "    # List with k values that will be tested\n",
    "    k_list = [1,2,3,4,5,6,7,8,9,10,20,30,50,80]\n",
    "\n",
    "    # As k has to be 0 < k < min(Matrix.shape) in SVD the values in k_list that are higher are filtered out.\n",
    "    # The shape of the items in the matrix is passed with csr_matrix(dataset.pivot_table(index='userId', columns='itemId', values='rating').fillna(0).values).shape[1]\n",
    "    k_list = list(filter(lambda num: num < csr_matrix(dataset.pivot_table(index='userId', columns='itemId', values='rating').fillna(0).values).shape[1], k_list))\n",
    "    print(k_list)\n",
    "    \n",
    "    for k in k_list:\n",
    "        rmse_list = []\n",
    "        for i in range(0,iterations):\n",
    "            dataset_ex_masked, masked_data = train_test_split(dataset, test_size=.05)\n",
    "\n",
    "            dataset_ex_masked_csr = csr_matrix(dataset_ex_masked.pivot_table(index='userId', columns='itemId', values='rating').fillna(0).values)\n",
    "            masked_data_csr = csr_matrix(masked_data.pivot_table(index='userId', columns='itemId', values='rating').fillna(0).values)\n",
    "\n",
    "            rmse, mae = evaluate_predictions(calculate_svd_prediction(dataset_ex_masked_csr,k),masked_data_csr.toarray())\n",
    "            \n",
    "            rmse_list.append(rmse)\n",
    "    \n",
    "        results.append([k,(sum(rmse_list)/len(rmse_list))])\n",
    "        print('For k = {0}, the average rmse = {1}'.format(k,(sum(rmse_list)/len(rmse_list))))\n",
    "\n",
    "    best_parameters_svd = sorted(results, key=lambda x: x[1])[0]\n",
    "    print('The rmse is lowest for k = {0} at = {1}'.format(best_parameters_svd[0],best_parameters_svd[1]))\n",
    "    \n",
    "    return best_parameters_svd\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 Model Evaluation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 Performance Netflix Dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1.1 Results KNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_train_netflix, knn_validation_netflix, knn_test_netflix = train_test(filtered_netflix_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(282, 100)"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_validation_netflix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.8697475555586083, 'euclidean', 2], [2.652481111180618, 'euclidean', 5], [2.443846503403922, 'euclidean', 10], [2.2028551030641577, 'euclidean', 20], [1.9197583871516581, 'euclidean', 50], [1.6989420621525715, 'euclidean', 100], [1.325303093362727, 'euclidean', 500], [2.8652943564890103, 'cosine', 2], [2.638133976952043, 'cosine', 5], [2.4204157117320917, 'cosine', 10], [2.1618450667165994, 'cosine', 20], [1.853877998316221, 'cosine', 50], [1.6322988221988841, 'cosine', 100], [1.2203101333224995, 'cosine', 500], [2.8697475555586083, 'minkowski', 2], [2.652481111180618, 'minkowski', 5], [2.443846503403922, 'minkowski', 10], [2.2028551030641577, 'minkowski', 20], [1.9197583871516581, 'minkowski', 50], [1.6989420621525715, 'minkowski', 100], [1.325303093362727, 'minkowski', 500]]\n",
      "[1.2203101333224995, 'cosine', 500]\n"
     ]
    }
   ],
   "source": [
    "best_params_knn = hyper_parameter_tuning_knn(train_data = knn_train_netflix, validation_data = knn_validation_netflix,weighted = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55786, 40)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_21688\\3493099727.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mbest_params_w_knn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhyper_parameter_tuning_knn3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfiltered_jester_df\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mweighted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterations\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_21688\\1372646511.py\u001b[0m in \u001b[0;36mhyper_parameter_tuning_knn3\u001b[1;34m(dataset, weighted, iterations)\u001b[0m\n\u001b[0;32m     16\u001b[0m                 \u001b[0mknn_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mknn_validation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mknn_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mknn_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m                 \u001b[0mrmse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmae\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluate_predictions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mknn_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mknn_validation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetric\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mknn_validation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m                 \u001b[0mrmse_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrmse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_21688\\2005018782.py\u001b[0m in \u001b[0;36mcalculate_weighted_knn_prediction\u001b[1;34m(train_data, test_data, k, metric)\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0msim_users\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0musers_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0musers_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[0mmasked_ar\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmasked_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msim_users\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m         \u001b[0mmasked_ar_av\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maverage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmasked_ar\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m         \u001b[1;31m# Calculate the mean excluding NaN for each item and turn NaN values back to 0's (for items that have not been rated by all similar users) and add them to the prediction list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[0mknn_prediction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmasked_ar_av\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\vbraun\\Anaconda3\\lib\\site-packages\\numpy\\ma\\extras.py\u001b[0m in \u001b[0;36maverage\u001b[1;34m(a, axis, weights, returned)\u001b[0m\n\u001b[0;32m    622\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    623\u001b[0m         \u001b[0mscl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwgt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mresult_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 624\u001b[1;33m         \u001b[0mavg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwgt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mresult_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mscl\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    625\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    626\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mreturned\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\vbraun\\Anaconda3\\lib\\site-packages\\numpy\\ma\\core.py\u001b[0m in \u001b[0;36msum\u001b[1;34m(self, axis, dtype, out, keepdims)\u001b[0m\n\u001b[0;32m   5082\u001b[0m         \u001b[1;31m# No explicit output\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5083\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5084\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilled\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5085\u001b[0m             \u001b[0mrndim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ndim'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5086\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mrndim\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\vbraun\\Anaconda3\\lib\\site-packages\\numpy\\ma\\core.py\u001b[0m in \u001b[0;36mfilled\u001b[1;34m(self, fill_value)\u001b[0m\n\u001b[0;32m   3792\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3793\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3794\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'K'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3795\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3796\u001b[0m                 \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopyto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwhere\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_params_w_knn = hyper_parameter_tuning_knn3(dataset = filtered_jester_df,weighted = True, iterations = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected n_neighbors <= n_samples,  but n_samples = 5572, n_neighbors = 10000",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_21688\\3654562018.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mbest_params_w_knn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhyper_parameter_tuning_knn3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfiltered_netflix_df\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mweighted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterations\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_21688\\3886670549.py\u001b[0m in \u001b[0;36mhyper_parameter_tuning_knn3\u001b[1;34m(dataset, weighted, iterations)\u001b[0m\n\u001b[0;32m     15\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0miterations\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m                 \u001b[0mknn_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mknn_validation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mknn_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m                 \u001b[0mrmse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmae\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluate_predictions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mknn_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mknn_validation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetric\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mknn_validation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m                 \u001b[0mrmse_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrmse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_21688\\2005018782.py\u001b[0m in \u001b[0;36mcalculate_weighted_knn_prediction\u001b[1;34m(train_data, test_data, k, metric)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;31m# Find the closest distance with k amount of users for the passed 'test_data' (either the validation or test dataset depending on the stage)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mdistance\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mknn_model_fitted\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;31m# Create a sorted list including the distances and userId for each user in the test_data that we can iterate through\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\vbraun\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_base.py\u001b[0m in \u001b[0;36mkneighbors\u001b[1;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[0;32m    725\u001b[0m         \u001b[0mn_samples_fit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_samples_fit_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mn_neighbors\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mn_samples_fit\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m    728\u001b[0m                 \u001b[1;34m\"Expected n_neighbors <= n_samples, \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    729\u001b[0m                 \u001b[1;34m\" but n_samples = %d, n_neighbors = %d\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mn_samples_fit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_neighbors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Expected n_neighbors <= n_samples,  but n_samples = 5572, n_neighbors = 10000"
     ]
    }
   ],
   "source": [
    "best_params_w_knn = hyper_parameter_tuning_knn3(dataset = filtered_netflix_df,weighted = True, iterations = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For k = 2 using euclidean, the average rmse = 2.796661482177823\n",
      "For k = 50 using euclidean, the average rmse = 1.89821098416325\n",
      "For k = 75 using euclidean, the average rmse = 1.794685968589447\n",
      "For k = 100 using euclidean, the average rmse = 1.6875359473142528\n",
      "For k = 250 using euclidean, the average rmse = 1.4629415029559638\n",
      "For k = 1000 using euclidean, the average rmse = 1.2241047823616262\n",
      "For k = 5000 using euclidean, the average rmse = 1.0628570636038384\n",
      "For k = 2 using cosine, the average rmse = 2.8077625800320534\n",
      "For k = 50 using cosine, the average rmse = 1.8143854933118722\n",
      "For k = 75 using cosine, the average rmse = 1.6684302252908307\n",
      "For k = 100 using cosine, the average rmse = 1.5693042630498837\n",
      "For k = 250 using cosine, the average rmse = 1.3181489971698281\n",
      "For k = 1000 using cosine, the average rmse = 1.1304141796772604\n",
      "For k = 5000 using cosine, the average rmse = 1.0602141355072878\n",
      "For k = 2 using minkowski, the average rmse = 2.8109639073117956\n",
      "For k = 50 using minkowski, the average rmse = 1.8814446509908271\n",
      "For k = 75 using minkowski, the average rmse = 1.7597889413756775\n",
      "For k = 100 using minkowski, the average rmse = 1.6836448927898242\n",
      "For k = 250 using minkowski, the average rmse = 1.4348136876375912\n",
      "For k = 1000 using minkowski, the average rmse = 1.223136726605357\n",
      "For k = 5000 using minkowski, the average rmse = 1.0728602458514749\n",
      "[[2.796661482177823, 'euclidean', 2], [1.89821098416325, 'euclidean', 50], [1.794685968589447, 'euclidean', 75], [1.6875359473142528, 'euclidean', 100], [1.4629415029559638, 'euclidean', 250], [1.2241047823616262, 'euclidean', 1000], [1.0628570636038384, 'euclidean', 5000], [2.8077625800320534, 'cosine', 2], [1.8143854933118722, 'cosine', 50], [1.6684302252908307, 'cosine', 75], [1.5693042630498837, 'cosine', 100], [1.3181489971698281, 'cosine', 250], [1.1304141796772604, 'cosine', 1000], [1.0602141355072878, 'cosine', 5000], [2.8109639073117956, 'minkowski', 2], [1.8814446509908271, 'minkowski', 50], [1.7597889413756775, 'minkowski', 75], [1.6836448927898242, 'minkowski', 100], [1.4348136876375912, 'minkowski', 250], [1.223136726605357, 'minkowski', 1000], [1.0728602458514749, 'minkowski', 5000]]\n",
      "[1.0602141355072878, 'cosine', 5000]\n"
     ]
    }
   ],
   "source": [
    "best_params_uw_knn = hyper_parameter_tuning_knn3(dataset = filtered_netflix_df,weighted = False, iterations = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.2453031136284058, 0.9788639535659068)"
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_predictions(calculate_weighted_knn_prediction(train_data = knn_train_netflix, test_data = knn_test_netflix, metric = best_params_knn[1], k = best_params_knn[2]),knn_test_netflix.toarray())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1.2 Results SVD model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating the average rmse over 10 iterations\n",
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 20, 30, 50, 80]\n",
      "For k = 1, the average rmse = 3.284667597876586\n",
      "For k = 2, the average rmse = 3.288383219599479\n",
      "For k = 3, the average rmse = 3.245797267413888\n",
      "For k = 4, the average rmse = 3.2694475188379526\n",
      "For k = 5, the average rmse = 3.2947039392406987\n",
      "For k = 6, the average rmse = 3.3091377340543486\n",
      "For k = 7, the average rmse = 3.346076542695086\n",
      "For k = 8, the average rmse = 3.25778620707464\n",
      "For k = 9, the average rmse = 3.315959401174073\n",
      "For k = 10, the average rmse = 3.3168548785250516\n",
      "For k = 20, the average rmse = 3.346089453580742\n",
      "For k = 30, the average rmse = 3.3959738032956346\n",
      "For k = 50, the average rmse = 3.3596617285108543\n",
      "For k = 80, the average rmse = 3.382680847313246\n",
      "The rmse is lowest for k = 3 at = 3.245797267413888\n"
     ]
    }
   ],
   "source": [
    "best_params_svd = hyper_parameter_tuning_svd(dataset = filtered_netflix_df, iterations = 10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1.3 Comparison KNN & SVD for Netflix"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1.3.1 Performance"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1.3.2 Recommendations"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 Performance Jester Dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.1 Results KNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_train_jester, knn_validation_jester, knn_test_jester = train_test(filtered_jester_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_21688\\1819214268.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mbest_params_knn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhyper_parameter_tuning_knn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mknn_train_jester\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mknn_validation_jester\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mweighted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_21688\\2874395102.py\u001b[0m in \u001b[0;36mhyper_parameter_tuning_knn\u001b[1;34m(train_data, validation_data, weighted)\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mn_neighbors\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m             \u001b[0mrmse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmae\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluate_predictions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetric\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m             \u001b[0mhpt_results\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrmse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmet\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_21688\\2940763307.py\u001b[0m in \u001b[0;36mcalculate_weighted_knn_prediction\u001b[1;34m(train_data, test_data, k, metric)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;31m# Find the closest distance with k amount of users for the passed 'test_data' (either the validation or test dataset depending on the stage)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mdistance\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mknn_model_fitted\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;31m# Create a sorted list including the distances and userId for each user in the test_data that we can iterate through\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\vbraun\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_base.py\u001b[0m in \u001b[0;36mkneighbors\u001b[1;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[0;32m    750\u001b[0m                 \u001b[0mkwds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meffective_metric_params_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    751\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 752\u001b[1;33m             chunked_results = list(\n\u001b[0m\u001b[0;32m    753\u001b[0m                 pairwise_distances_chunked(\n\u001b[0;32m    754\u001b[0m                     \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\vbraun\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\pairwise.py\u001b[0m in \u001b[0;36mpairwise_distances_chunked\u001b[1;34m(X, Y, reduce_func, metric, n_jobs, working_memory, **kwds)\u001b[0m\n\u001b[0;32m   1724\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mreduce_func\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1725\u001b[0m             \u001b[0mchunk_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mD_chunk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1726\u001b[1;33m             \u001b[0mD_chunk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreduce_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mD_chunk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1727\u001b[0m             \u001b[0m_check_chunk_size\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mD_chunk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchunk_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1728\u001b[0m         \u001b[1;32myield\u001b[0m \u001b[0mD_chunk\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\vbraun\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_base.py\u001b[0m in \u001b[0;36m_kneighbors_reduce_func\u001b[1;34m(self, dist, start, n_neighbors, return_distance)\u001b[0m\n\u001b[0;32m    632\u001b[0m         \"\"\"\n\u001b[0;32m    633\u001b[0m         \u001b[0msample_range\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 634\u001b[1;33m         \u001b[0mneigh_ind\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margpartition\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_neighbors\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    635\u001b[0m         \u001b[0mneigh_ind\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mneigh_ind\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[0mn_neighbors\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    636\u001b[0m         \u001b[1;31m# argpartition doesn't guarantee sorted order, so we sort again\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36margpartition\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\vbraun\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36margpartition\u001b[1;34m(a, kth, axis, kind, order)\u001b[0m\n\u001b[0;32m    837\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    838\u001b[0m     \"\"\"\n\u001b[1;32m--> 839\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'argpartition'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkind\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    840\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    841\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\vbraun\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mbound\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     58\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m         \u001b[1;31m# A TypeError occurs if the object does have such a method in its\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_params_knn = hyper_parameter_tuning_knn(train_data = knn_train_jester, validation_data = knn_validation_jester,weighted = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_predictions(knn_test_jester.toarray(),calculate_knn_prediction(train_data = knn_train_jester, test_data = knn_test_jester, metric = best_params_knn[1], k = best_params_knn[2], n_neighbors = best_params_knn[3]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.2 Results SVD model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_svd = hyper_parameter_tuning_svd(dataset = filtered_jester_df, iterations = 2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.3 Comparison KNN & SVD for Jester"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1.3.1 Performance"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1.3.2 Recommendations"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recommend_for_user = 50\n",
    "\n",
    "# user_pred_df = pd.DataFrame(predictions)\n",
    "# user_sel_pred_df = user_pred_df.loc[recommend_for_user].sort_values(ascending=False)\n",
    "\n",
    "# user_df = pd.DataFrame(final_csr_matrix.toarray())\n",
    "# selected = pd.DataFrame(user_df.loc[recommend_for_user])\n",
    "# rated_movies = selected.loc[~(selected==0).all(axis=1)].index.values.tolist()\n",
    "\n",
    "# recommended_movies = user_sel_pred_df.loc[~user_sel_pred_df.index.isin(rated_movies)]\n",
    "\n",
    "# print('Rated items are:',rated_movies)\n",
    "# print(recommended_movies[:3])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVD:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# final_csr_matrix = csr_matrix(filtered_df.pivot_table(index='userId', columns='itemId', values='rating').fillna(0).values)\n",
    "# predictions = hyper_svd(final_csr_matrix,best_parameters_svd[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recommend_for_user = 650\n",
    "\n",
    "# user_pred_df = pd.DataFrame(predictions)\n",
    "# user_sel_pred_df = user_pred_df.loc[recommend_for_user].sort_values(ascending=False)\n",
    "\n",
    "# user_df = pd.DataFrame(final_csr_matrix.toarray())\n",
    "# selected = pd.DataFrame(user_df.loc[recommend_for_user])\n",
    "# rated_movies = selected.loc[~(selected==0).all(axis=1)].index.values.tolist()\n",
    "\n",
    "# recommended_movies = user_sel_pred_df.loc[~user_sel_pred_df.index.isin(rated_movies)]\n",
    "\n",
    "# print('Rated items are:',rated_movies)\n",
    "# print(recommended_movies[:3])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to answer the subquestion: \"How do the KNN and SVD models compare?\" we will compare compare the rmse of both models for the same dataset."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7 Conclusion"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Which type of RecSys based on CF could Netflix user to provide the most accurate recommendations to users?\n",
    "\n",
    "- How do KNN and SVD compare?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
