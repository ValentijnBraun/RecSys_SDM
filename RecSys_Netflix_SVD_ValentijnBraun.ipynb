{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Introduction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The applications of recommender systems in businesses have become increasingly popular. Recommender systems apply various sources of information including demographics, social, and preferences to provide users with tailored recommended items. Moreover, the favoured technique for building recommender systems is Collaborative filtering. This technique is further divided into three main categories including Memory-Based, Model-Based, and Hybrid-BAsed. Therefore, as large businesses realise the advantages of recommending personalized items to users, the research for techniques, sources of information, and implementation grows. Netflix is among the big organisations interested in the expansion of recommmender system. The application of recommender systems at Netflix is widely known, however improvements are continiously being investigated to provide users with the best movie and series recommendations. Thus, this notebook aims to investigate the application of collaborative filtering techniques for Netflix.      "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Which type of RecSys based on CF could Netflix user to provide the most accurate recommendations to users?\n",
    "\n",
    "- What are the different type of RecSys based on CF?\n",
    "- Which types could be used for Netflix' dataset?\n",
    "- How do KNN and SVD compare?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Importing Libraries"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General imports\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Used for visualisations in the EDA\n",
    "import seaborn as sns\n",
    "\n",
    "# Used in reducing the memory storage of sparse matrices\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "# Used for creating a KNN and SVD RecSys model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from scipy.sparse.linalg import svds\n",
    "\n",
    "# Used for performance evaluation\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# As working with NaN values in matrices overwelmed the output with warnings \n",
    "# these warnings will be ignored.\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "debugging = True"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Netflix Dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.1 Import Source Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code to append movieId to each record in all of the source files if this has not been executed earlier. This will allow all the source files to be loaded into a dataframe with one line of code and without having to add the movieId seperately before concatting the sourcefiles. This additionally resulted in a faster importing time of the source data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_netflix_source():\n",
    "    # Variable to keep track of which movieId has to be appended\n",
    "    x = 0\n",
    "    string = \",\"+str(x)\n",
    "\n",
    "    # Loop through each file in the directory\n",
    "    for filename in os.listdir(directory):\n",
    "        with open(os.path.join(directory, filename), 'r') as f:\n",
    "            # Check if the first line of the first file already has been formatted\n",
    "            # If true formatting the source will be skipped\n",
    "            if(f.readlines()[0] == '1:,1\\n'):\n",
    "                print('Source is already formatted, continuing \\n')\n",
    "                return\n",
    "            else:\n",
    "                print('Started formatting source files \\n')\n",
    "                # Append a ',', movieId and \\n (newline) to each line resulting in an extra column with movieId when using pandas read_csv \n",
    "                file_lines = [''.join([x.strip(), string, '\\n']) for x in f.readlines()]\n",
    "        with open(os.path.join(directory, filename), 'w') as f:\n",
    "            # Save the formatted file\n",
    "            f.writelines(file_lines)\n",
    "            print('Completed formatting source files')\n",
    "    return"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the movie dataframe by concatting all the sourcefiles without their title (skiprows=1). Concluding with naming the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source is already formatted, continuing \n",
      "\n",
      "Started concatting all source files to DataFrame \n",
      "\n",
      "Completed concatting all source files to DataFrame \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>rating</th>\n",
       "      <th>itemId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1488844</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>822109</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>885013</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    userId  rating  itemId\n",
       "0  1488844       3       1\n",
       "1   822109       5       1\n",
       "2   885013       4       1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the folder in which all the seperate movie files are located\n",
    "directory = \"/Users/vbraun/Downloads/training_set/\"\n",
    "\n",
    "# Run the function to format the source data if necessary\n",
    "format_netflix_source()\n",
    "\n",
    "print('Started concatting all source files to DataFrame \\n')\n",
    "# Performing 1 concat on all sourcefiles to create one dataframe (including itemId)\n",
    "# As the files do not have a header and differ between each other 'header' = None and the first row will be skipped\n",
    "netflix_df = pd.concat(pd.read_csv(os.path.join(directory, fname), skiprows=1,header=None) for fname in os.listdir(directory)).rename(columns={0:'userId',1:'rating',2:'date',3:'itemId'})\n",
    "print('Completed concatting all source files to DataFrame \\n')\n",
    "\n",
    "# Dropping the date column as this is not relevant for this recommender system\n",
    "netflix_df = netflix_df.drop(columns='date')\n",
    "\n",
    "display(netflix_df.head(3))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.2 Data Filtering"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To allow for faster development a debugging variable is used. If debugging is True the dataset will only consist of the first 100 movies. For the final model, debugging will be set to False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Debugging is set to True: limiting the dataset to the first 100 movies\n",
      "Length of selected dataset: 352771 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# In order to achieve faster execution time of the while developing a selection of the total dataset is made when debugging = True\n",
    "if debugging == True:\n",
    "    print('Debugging is set to True: limiting the dataset to the first 100 movies')\n",
    "    filtered_netflix_df = netflix_df[netflix_df['itemId'] <= 100]\n",
    "else:\n",
    "    filtered_netflix_df = netflix_df\n",
    "print('Length of selected dataset: {0} \\n'.format(len(filtered_netflix_df)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to filter the dataset based on activity and reduce the sparsity of the data, the data will be grouped and filtered based on movies and users. The datasets will show how many ratings each movie has gotten and how many rating each user has given."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To reduce the sparcity of data in the dataset, we will filter out the users that have rated fewer than 5% of the total amount of movies."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the movies that have been rated by fewer than 50 people will be filtered out of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering out users that have rated less than 5% of all items\n",
      "Length of filtered dataset: 44209 \n",
      "\n",
      "Filtering out movies that have been rated by fewer than 50 users\n",
      "Length of filtered dataset: 44209\n"
     ]
    }
   ],
   "source": [
    "# Making two dataframes: One grouping items to show how many ratings an item has gotten and one grouping users to show how many ratings an user has given\n",
    "filtered_movie_count = filtered_netflix_df[['itemId','userId']].groupby('itemId').count().reset_index().rename(columns={'userId':'user_count'})\n",
    "filtered_user_count = filtered_netflix_df[['itemId','userId']].groupby('userId').count().reset_index().rename(columns={'itemId':'item_count'})\n",
    "\n",
    "# Defining the minimal percentage of items that a user has to have rated to be included\n",
    "required_rated_percentage = 0.05\n",
    "print('Filtering out users that have rated less than {0}% of all movies'.format(int(required_rated_percentage*100)))\n",
    "\n",
    "# Check if the userId exists when the total amount of items rated by a user (filtered_user_count['item_count']), divided by the total amount of movies (len(filtered_movie_count)' is bigger than the required_rated_percentage\n",
    "filtered_netflix_df = filtered_netflix_df[filtered_netflix_df['userId'].isin(filtered_user_count[filtered_user_count['item_count']/len(filtered_movie_count) > required_rated_percentage]['userId'])]\n",
    "print('Length of filtered dataset: {0} \\n'.format(len(filtered_netflix_df)))\n",
    "\n",
    "print('Filtering out movies that have been rated by fewer than {0} users'.format(50))\n",
    "filtered_netflix_df = filtered_netflix_df[filtered_netflix_df['itemId'].isin(filtered_movie_count[filtered_movie_count['user_count']>50]['itemId'])]\n",
    "print('Length of filtered dataset:',len(filtered_netflix_df))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Jester Dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.1 Import Source Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating dataframes for the jester datasets\n",
    "jester_items = pd.read_csv(r'C:\\Users\\vbraun\\Downloads\\SDM-Datasets\\jester_items.csv')\n",
    "jester_ratings = pd.read_csv(r'C:\\Users\\vbraun\\Downloads\\SDM-Datasets\\jester_ratings.csv')\n",
    "\n",
    "# Rename jokeId to itemId to have one uniform format for the Netflix and Jester dataset\n",
    "jester_df = jester_ratings.rename(columns={'jokeId':'itemId'})\n",
    "\n",
    "# The ratings given in the jester dataset range from -10 to 10. Since calculations including average ratings of users could be influenced by this, the ratings will be increase with 10 to range from 0 - 20. \n",
    "jester_df['rating'] = jester_df['rating'] + 10"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2 Data filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Debugging is set to True: limiting the dataset to the first 50 jokes\n",
      "Length of selected dataset: 715403 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# In order to achieve faster execution time of the while developing a selection of the total dataset is made when debugging = True\n",
    "if debugging == True:\n",
    "    print('Debugging is set to True: limiting the dataset to the first 50 jokes')\n",
    "    filtered_jester_df = jester_df[jester_df['itemId'] <= 50]\n",
    "else:\n",
    "    filtered_jester_df = jester_df\n",
    "print('Length of selected dataset: {0} \\n'.format(len(filtered_jester_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making two dataframes: One grouping items to show how many ratings an item has gotten and one grouping users to show how many ratings an user has given\n",
    "jester_item_count = filtered_jester_df[['itemId','userId']].groupby('itemId').count().reset_index().rename(columns={'userId':'user_count'})\n",
    "jester_user_count = filtered_jester_df[['itemId','userId']].groupby('userId').count().reset_index().rename(columns={'itemId':'item_count'})\n",
    "\n",
    "# Defining the minimal percentage of items that a user has to have rated to be included\n",
    "required_rated_percentage = 0.05\n",
    "print('Filtering out users that have rated less than {0}% of all jokes'.format(int(required_rated_percentage*100)))\n",
    "\n",
    "# Check if the userId exists when the total amount of items rated by a user (jester_user_count['item_count']), divided by the total amount of movies (len(jester_item_count)' is bigger than the required_rated_percentage\n",
    "filtered_jester_df = filtered_jester_df[filtered_jester_df['userId'].isin(jester_user_count[jester_user_count['item_count']/len(jester_item_count) > required_rated_percentage]['userId'])]\n",
    "print('Length of filtered dataset: {0} \\n'.format(len(filtered_jester_df)))\n",
    "\n",
    "print('Filtering out jokes that have been rated by fewer than {0} users'.format(20))\n",
    "filtered_jester_df = filtered_jester_df[filtered_jester_df['itemId'].isin(jester_item_count[jester_item_count['user_count']>20]['itemId'])]\n",
    "print('Length of filtered dataset:',len(filtered_jester_df))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 EDA Netflix Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('The filtered dataset has', filtered_df['userId'].nunique(), 'unique users')\n",
    "# print('The filtered dataset has', filtered_df['itemId'].nunique(), 'unique movies')\n",
    "# print('The filtered dataset has', filtered_df['rating'].nunique(), 'unique ratings')\n",
    "# print('The unique ratings are', sorted(filtered_df['rating'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(filtered_df.head(),filtered_df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtered_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Amount of NaN values in the dataset:',filtered_df.loc[lambda x: x.isnull().any(axis=1)].shape[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following graph shows for each movie (as a dot) what its mean rating is in comparison to the total amount of ratings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt = sns.jointplot(x='rating_mean', y='rating_amount', data=filtered_df.groupby('itemId').agg(rating_mean = ('rating', 'mean'), rating_amount = ('rating', 'count')).reset_index())\n",
    "# plt.fig.suptitle(\"Rating Mean and Rating Amount of Movies\")\n",
    "# plt.fig.subplots_adjust(top=0.95)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notably, movies with low mean ratings have generally been rated a low number of times in relation to movies with a mean rating higher than 3.0."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next graph shows the same variables as the graph seen above for each user. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt = sns.jointplot(x='rating_mean', y='rating_amount', data=filtered_df.groupby('userId').agg(rating_mean = ('rating', 'mean'), rating_amount = ('rating', 'count')).reset_index())\n",
    "# plt.fig.suptitle(\"Rating Mean and Rating Amount of Users\")\n",
    "# plt.fig.subplots_adjust(top=0.95)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The graph for users show that there are several outliers of users that have rated many movies while having a low mean of their ratings. Additionally, the graph shows that mean of the rating mean approaches normality. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 EDA Jester Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('The filtered dataset has', filtered_df['userId'].nunique(), 'unique users')\n",
    "# print('The filtered dataset has', filtered_df['itemId'].nunique(), 'unique movies')\n",
    "# print('The filtered dataset has', filtered_df['rating'].nunique(), 'unique ratings')\n",
    "# print('The unique ratings are', sorted(filtered_df['rating'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(filtered_df.head(),filtered_df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtered_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Amount of NaN values in the dataset:',filtered_df.loc[lambda x: x.isnull().any(axis=1)].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt = sns.jointplot(x='rating_mean', y='rating_amount', data=filtered_df.groupby('itemId').agg(rating_mean = ('rating', 'mean'), rating_amount = ('rating', 'count')).reset_index())\n",
    "# plt.fig.suptitle(\"Rating Mean and Rating Amount of Movies\")\n",
    "# plt.fig.subplots_adjust(top=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt = sns.jointplot(x='rating_mean', y='rating_amount', data=filtered_df.groupby('userId').agg(rating_mean = ('rating', 'mean'), rating_amount = ('rating', 'count')).reset_index())\n",
    "# plt.fig.suptitle(\"Rating Mean and Rating Amount of Users\")\n",
    "# plt.fig.subplots_adjust(top=0.95)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 Recommender Systems"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both models will be evaluated using the same function that calculates the root mean squared error and the mean absolute error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_predictions(pred, truth):\n",
    "    # In order to only compare y's that were not 0, a selection is made from y and corresponding the y^ where y != 0 by using .nonzero() \n",
    "    pred = pred[truth.nonzero()].flatten()\n",
    "    truth = truth[truth.nonzero()].flatten()\n",
    "\n",
    "    # Standard RMSE and MAE calculations\n",
    "    rmse = np.sqrt(mean_squared_error(pred,truth))\n",
    "    mae = mean_absolute_error(pred,truth)\n",
    "    \n",
    "    return rmse, mae"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 K Nearest Neighbors (KNN)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.1 KNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test(filtered_df):\n",
    "    # Since the data is sparse the pivot_table is performed in the csr_matrix to reduce the required memory \n",
    "    sparse_matrix = csr_matrix(filtered_df.pivot_table(index='userId', columns='itemId', values='rating').fillna(0).values)\n",
    "    print(sparse_matrix.check_format)\n",
    "\n",
    "    # To train and evaluate the KNN model the sparse matrix is split into 70% train, 15% validation and 15% test data\n",
    "    train_data, test_data = train_test_split(sparse_matrix, test_size=.30)\n",
    "    test_data, validation_data = train_test_split(test_data, test_size=.50)\n",
    "\n",
    "    return train_data, validation_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_knn_prediction(train_data, test_data, k = 5, metric = 'cosine', n_neighbors = 20):\n",
    "    knn_model = NearestNeighbors(metric=metric,algorithm='brute',n_neighbors=n_neighbors,n_jobs=-1)\n",
    "\n",
    "    knn_model_fitted = knn_model.fit(train_data.toarray())\n",
    "    distance, indices = knn_model_fitted.kneighbors(test_data.toarray(),k)\n",
    "\n",
    "    raw_recommends = sorted(list(zip(indices.squeeze().tolist(), distance.squeeze().tolist())), key=lambda x: x[1])[:0:-1]\n",
    "    knn_prediction = []\n",
    "    for i, (idx, dist) in enumerate(raw_recommends):\n",
    "        td = pd.DataFrame(train_data.toarray())\n",
    "        sim_users = np.array(td[td.index.isin(idx)])\n",
    "        sim_users[sim_users == 0] = np.nan\n",
    "        average_rat = np.nan_to_num(np.nanmean(sim_users,axis=0))\n",
    "        knn_prediction.append(average_rat)\n",
    "    \n",
    "    return np.array(knn_prediction)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.2 KNN Hyper Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyper_parameter_tuning_knn(train_data, validation_data):\n",
    "    n_neighbors = [5,10,20,50]\n",
    "    recommendation_amount = [3,5,10]\n",
    "    metric = ['euclidean','cosine','minkowski']\n",
    "\n",
    "    hpt_results = []\n",
    "    for met in metric:\n",
    "        for k in recommendation_amount:\n",
    "            for n in n_neighbors:\n",
    "                rmse, mae = evaluate_predictions(validation_data.toarray(),calculate_knn_prediction(train_data = train_data, test_data = validation_data, metric = met, k = k, n_neighbors = n))\n",
    "                print(rmse,met,k,n)\n",
    "                hpt_results.append([rmse,met,k,n])\n",
    "\n",
    "    best_parameters_knn = sorted(hpt_results, key=lambda x: x[0])[0]\n",
    "    print(best_parameters_knn)\n",
    "\n",
    "    return best_parameters_knn"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Create NearestNeighbors model\n",
    "1. Fit the model with train data\n",
    "1. Use kneighbors to find the k amount of neighbors of the jokes in the test data\n",
    "1. Calculate the prediction by taking the average score of the k most similar jokes\n",
    "1. Evaluate the model by comparing the actual ratings with the predicted ratings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algorithm is set at brute (force) because the inputdata is sparse"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Singular Value Decomposition (SVD)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.1 SVD Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pivot the dataset into a matrix with index='userId', columns='itemId', values='rating' in order to later perform user-based collaborative filtering. Moreover, fill_value = 0 in order to remove NaN values and save them as 0. Finally, the matrix is directly stored as a sparse matrix to save memory, instead of first saving the entire matrix into memory. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scipy.sparse.linalg.svds was used to perform a partial singular value decomposition of a sparse matrix. This function allows us to specify 'k' which is the number of singular values and singular vectors that have to be computed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_svd_prediction(data, k = 5):\n",
    "    # Performing the SVD matrix factorisation giving: u (m x r) orthogonal matrix, \n",
    "    # s (r x r) diagonal matrix, and vt(ransposed) (r x n) orthogonal matrix.\n",
    "    u, s, vt = svds(data.toarray(), k = k)\n",
    "\n",
    "    # A diagonal matrix has to be created for s in order to recreate a matrix from u, s, and vt\n",
    "    s_diagonal = np.diag(s)\n",
    "\n",
    "    # Recreate the matrix by performing matrix multiplications of u, s, and vt\n",
    "    predictions = np.dot(np.dot(u, s_diagonal), vt)\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to evaluate the performance of the recommendations following SVD we only need the $\\hat{y}$ of existing $y$. Therefore, all other values will be filtered out of the prediction dataset by using pred[truth.nonzero()]. Afterwards we are able to evaluate the performance of our model by comparing $\\hat{y}$ with their corresponding $y$. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.2 SVD Hyper Parameter Tuning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different k values lead to different predictions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will perform hyperparameter tuning to find the k with the lowest rmse. For each k we will perform multiple iterations, in which a random sample of the data will be masked and used to calculate the rmse. The rmse of a k value will be the average rmse of all iterations of that k. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyper_parameter_tuning_svd(dataset, iterations = 10):\n",
    "    results = []\n",
    "    print('Calculating the average rmse over {0} iterations'.format(iterations))\n",
    "\n",
    "    # List with k values that will be tested\n",
    "    k_list = [1,2,3,4,5,6,7,8,9,10,20,30,50,80]\n",
    "\n",
    "    # As k has to be 0 < k < min(Matrix.shape) in SVD the values in k_list that are higher are filtered out.\n",
    "    # The shape of the items in the matrix is passed with csr_matrix(dataset.pivot_table(index='userId', columns='itemId', values='rating').fillna(0).values).shape[1]\n",
    "    k_list = list(filter(lambda num: num < csr_matrix(dataset.pivot_table(index='userId', columns='itemId', values='rating').fillna(0).values).shape[1], k_list))\n",
    "    print(k_list)\n",
    "    \n",
    "    for k in k_list:\n",
    "        rmse_list = []\n",
    "        for i in range(0,iterations):\n",
    "            dataset_ex_masked, masked_data = train_test_split(dataset, test_size=.05)\n",
    "\n",
    "            dataset_ex_masked_csr = csr_matrix(dataset_ex_masked.pivot_table(index='userId', columns='itemId', values='rating').fillna(0).values)\n",
    "            masked_data_csr = csr_matrix(masked_data.pivot_table(index='userId', columns='itemId', values='rating').fillna(0).values)\n",
    "\n",
    "            rmse, mae = evaluate_predictions(calculate_svd_prediction(dataset_ex_masked_csr,k),masked_data_csr.toarray())\n",
    "            \n",
    "            rmse_list.append(rmse)\n",
    "    \n",
    "        results.append([k,(sum(rmse_list)/len(rmse_list))])\n",
    "        print('For k = {0}, the average rmse = {1}'.format(k,(sum(rmse_list)/len(rmse_list))))\n",
    "\n",
    "    best_parameters_svd = sorted(results, key=lambda x: x[1])[0]\n",
    "    print('The rmse is lowest for k = {0} at = {1}'.format(best_parameters_svd[0],best_parameters_svd[1]))\n",
    "    \n",
    "    return best_parameters_svd\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 Model Evaluation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 Performance Netflix Dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1.1 Results KNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_train, knn_validation, knn_test = train_test(filtered_netflix_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.623055009576771 euclidean 3 5\n",
      "2.623055009576771 euclidean 3 10\n",
      "2.623055009576771 euclidean 3 20\n",
      "2.623055009576771 euclidean 3 50\n",
      "2.538732452423058 euclidean 5 5\n",
      "2.538732452423058 euclidean 5 10\n",
      "2.538732452423058 euclidean 5 20\n",
      "2.538732452423058 euclidean 5 50\n",
      "2.4509703519004 euclidean 10 5\n",
      "2.4509703519004 euclidean 10 10\n",
      "2.4509703519004 euclidean 10 20\n",
      "2.4509703519004 euclidean 10 50\n",
      "2.7771249981708976 cosine 3 5\n",
      "2.7771249981708976 cosine 3 10\n",
      "2.7771249981708976 cosine 3 20\n",
      "2.7771249981708976 cosine 3 50\n",
      "2.7501424757697457 cosine 5 5\n",
      "2.7501424757697457 cosine 5 10\n",
      "2.7501424757697457 cosine 5 20\n",
      "2.7501424757697457 cosine 5 50\n",
      "2.7139979666763248 cosine 10 5\n",
      "2.7139979666763248 cosine 10 10\n",
      "2.7139979666763248 cosine 10 20\n",
      "2.7139979666763248 cosine 10 50\n",
      "2.623055009576771 minkowski 3 5\n",
      "2.623055009576771 minkowski 3 10\n",
      "2.623055009576771 minkowski 3 20\n",
      "2.623055009576771 minkowski 3 50\n",
      "2.538732452423058 minkowski 5 5\n",
      "2.538732452423058 minkowski 5 10\n",
      "2.538732452423058 minkowski 5 20\n",
      "2.538732452423058 minkowski 5 50\n",
      "2.4509703519004 minkowski 10 5\n",
      "2.4509703519004 minkowski 10 10\n",
      "2.4509703519004 minkowski 10 20\n",
      "2.4509703519004 minkowski 10 50\n",
      "[2.4509703519004, 'euclidean', 10, 5]\n"
     ]
    }
   ],
   "source": [
    "best_params_knn = hyper_parameter_tuning_knn(train_data = knn_train, validation_data = knn_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.429720432043772, 2.1248197640488926)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_predictions(knn_test.toarray(),calculate_knn_prediction(train_data = knn_train, test_data = knn_test, metric = best_params_knn[1], k = best_params_knn[2], n_neighbors = best_params_knn[3]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1.2 Results SVD model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating the average rmse over 10 iterations\n",
      "For k = 1, the average rmse = 3.2914045440830813\n",
      "For k = 2, the average rmse = 3.3032158167079757\n",
      "For k = 3, the average rmse = 3.3190726110889743\n",
      "For k = 4, the average rmse = 3.313065654238047\n",
      "For k = 5, the average rmse = 3.3721363127371595\n",
      "For k = 6, the average rmse = 3.315092224347321\n",
      "For k = 7, the average rmse = 3.2735355994253643\n",
      "For k = 8, the average rmse = 3.3544884783067004\n",
      "For k = 9, the average rmse = 3.311079299177652\n",
      "For k = 10, the average rmse = 3.337231803280313\n",
      "For k = 20, the average rmse = 3.2723853079844942\n",
      "For k = 30, the average rmse = 3.3463953145666445\n",
      "For k = 50, the average rmse = 3.3863219001530007\n",
      "For k = 80, the average rmse = 3.39113859615619\n",
      "The rmse is lowest for k = 20 at = 3.2723853079844942\n"
     ]
    }
   ],
   "source": [
    "best_params_svd = hyper_parameter_tuning_svd(dataset = filtered_netflix_df, iterations = 10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1.3 Comparison KNN & SVD for Netflix"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1.3.1 Performance"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1.3.2 Recommendations"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 Performance Jester Dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.1 Results KNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_train, knn_validation, knn_test = train_test(filtered_jester_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.033372224544578 euclidean 3 5\n",
      "9.033372224544578 euclidean 3 10\n",
      "9.033372224544578 euclidean 3 20\n",
      "9.033372224544578 euclidean 3 50\n",
      "8.910130010204323 euclidean 5 5\n",
      "8.910130010204323 euclidean 5 10\n",
      "8.910130010204323 euclidean 5 20\n",
      "8.910130010204323 euclidean 5 50\n",
      "8.76778828052912 euclidean 10 5\n",
      "8.76778828052912 euclidean 10 10\n",
      "8.76778828052912 euclidean 10 20\n",
      "8.76778828052912 euclidean 10 50\n",
      "9.463540730309592 cosine 3 5\n",
      "9.463540730309592 cosine 3 10\n",
      "9.463540730309592 cosine 3 20\n",
      "9.463540730309592 cosine 3 50\n",
      "9.349449156099086 cosine 5 5\n",
      "9.349449156099086 cosine 5 10\n",
      "9.349449156099086 cosine 5 20\n",
      "9.349449156099086 cosine 5 50\n",
      "9.23628444832392 cosine 10 5\n",
      "9.23628444832392 cosine 10 10\n",
      "9.23628444832392 cosine 10 20\n",
      "9.23628444832392 cosine 10 50\n",
      "9.033372224544578 minkowski 3 5\n",
      "9.033372224544578 minkowski 3 10\n",
      "9.033372224544578 minkowski 3 20\n",
      "9.033372224544578 minkowski 3 50\n",
      "8.910130010204323 minkowski 5 5\n",
      "8.910130010204323 minkowski 5 10\n",
      "8.910130010204323 minkowski 5 20\n",
      "8.910130010204323 minkowski 5 50\n",
      "8.76778828052912 minkowski 10 5\n",
      "8.76778828052912 minkowski 10 10\n",
      "8.76778828052912 minkowski 10 20\n",
      "8.76778828052912 minkowski 10 50\n",
      "[8.76778828052912, 'euclidean', 10, 5]\n"
     ]
    }
   ],
   "source": [
    "best_params_knn = hyper_parameter_tuning_knn(train_data = knn_train, validation_data = knn_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8.73842878841048, 7.3428941454196375)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_predictions(knn_test.toarray(),calculate_knn_prediction(train_data = knn_train, test_data = knn_test, metric = best_params_knn[1], k = best_params_knn[2], n_neighbors = best_params_knn[3]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.2 Results SVD model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating the average rmse over 2 iterations\n",
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 20, 30]\n",
      "For k = 1, the average rmse = 8.530042083820124\n",
      "For k = 2, the average rmse = 8.868934041400944\n",
      "For k = 3, the average rmse = 8.988529151964887\n",
      "For k = 4, the average rmse = 9.11775329691272\n",
      "For k = 5, the average rmse = 9.142603298280465\n",
      "For k = 6, the average rmse = 9.23717779901505\n",
      "For k = 7, the average rmse = 9.299385331053614\n",
      "For k = 8, the average rmse = 9.325726077453089\n",
      "For k = 9, the average rmse = 9.452114322926636\n",
      "For k = 10, the average rmse = 9.543293105701935\n",
      "For k = 20, the average rmse = 9.899036402990543\n",
      "For k = 30, the average rmse = 9.949725169304354\n",
      "The rmse is lowest for k = 1 at = 8.530042083820124\n"
     ]
    }
   ],
   "source": [
    "best_params_svd = hyper_parameter_tuning_svd(dataset = filtered_jester_df, iterations = 2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.3 Comparison KNN & SVD for Jester"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1.3.1 Performance"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1.3.2 Recommendations"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predictions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_8716\\2686517655.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mrecommend_for_user\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0muser_pred_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0muser_sel_pred_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0muser_pred_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrecommend_for_user\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mascending\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'predictions' is not defined"
     ]
    }
   ],
   "source": [
    "recommend_for_user = 50\n",
    "\n",
    "user_pred_df = pd.DataFrame(predictions)\n",
    "user_sel_pred_df = user_pred_df.loc[recommend_for_user].sort_values(ascending=False)\n",
    "\n",
    "user_df = pd.DataFrame(final_csr_matrix.toarray())\n",
    "selected = pd.DataFrame(user_df.loc[recommend_for_user])\n",
    "rated_movies = selected.loc[~(selected==0).all(axis=1)].index.values.tolist()\n",
    "\n",
    "recommended_movies = user_sel_pred_df.loc[~user_sel_pred_df.index.isin(rated_movies)]\n",
    "\n",
    "print('Rated items are:',rated_movies)\n",
    "print(recommended_movies[:3])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVD:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# final_csr_matrix = csr_matrix(filtered_df.pivot_table(index='userId', columns='itemId', values='rating').fillna(0).values)\n",
    "# predictions = hyper_svd(final_csr_matrix,best_parameters_svd[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recommend_for_user = 650\n",
    "\n",
    "# user_pred_df = pd.DataFrame(predictions)\n",
    "# user_sel_pred_df = user_pred_df.loc[recommend_for_user].sort_values(ascending=False)\n",
    "\n",
    "# user_df = pd.DataFrame(final_csr_matrix.toarray())\n",
    "# selected = pd.DataFrame(user_df.loc[recommend_for_user])\n",
    "# rated_movies = selected.loc[~(selected==0).all(axis=1)].index.values.tolist()\n",
    "\n",
    "# recommended_movies = user_sel_pred_df.loc[~user_sel_pred_df.index.isin(rated_movies)]\n",
    "\n",
    "# print('Rated items are:',rated_movies)\n",
    "# print(recommended_movies[:3])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to answer the subquestion: \"How do the KNN and SVD models compare?\" we will compare compare the rmse of both models for the same dataset."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7 Conclusion"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Which type of RecSys based on CF could Netflix user to provide the most accurate recommendations to users?\n",
    "\n",
    "- How do KNN and SVD compare?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
